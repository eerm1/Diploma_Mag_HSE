{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e563ab-afc2-45bd-8449-dcf674759539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EMF import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5ee73f7-8104-4f8e-a63e-7b890875bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68375301-36ab-4f4d-9062-e1aa56e4b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from usertouser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e251e1-e1d8-403d-8382-d86f0d0835e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "261e1754-844f-4d27-bf09-45d4bcf9a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cor(user2user, ratings, u,v):\n",
    "    q1 = user2user.user_rated_items(u)\n",
    "    q2 = user2user.user_rated_items(v)\n",
    "    Ru = np.mean(ratings[ratings['userid'] == u]['rating'].tolist())\n",
    "    Rv = np.mean(ratings[ratings['userid'] == v]['rating'].tolist())\n",
    "    els = [e for e in q1 if e in q2]\n",
    "    den = []\n",
    "    en = []\n",
    "    for el in els:\n",
    "        rui = ratings.loc[(ratings['userid'] == u) & (ratings['itemid'] == el)]['rating'].tolist()[0]\n",
    "        rvi = ratings.loc[(ratings['userid'] == v) & (ratings['itemid'] == el)]['rating'].tolist()[0]\n",
    "        en.append((rui - Ru)*(rvi - Rv))\n",
    "        den.append((rui - Ru)**2 * (rvi - Rv) **2)\n",
    "    if len(den) == 0 or sum(den) == 0:\n",
    "        return 0 \n",
    "    else:\n",
    "        return np.sum(en) / np.sqrt(np.sum(den))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88dec892-b3ec-4bc5-a4a2-d561009ec620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explainable_score(user2user, users, items, ratings, theta=0):\n",
    "    \n",
    "    def _progress(count):\n",
    "        sys.stdout.write('\\rCompute Explainable score. Progress status : %.1f%%'%(float(count/len(users))*100.0))\n",
    "        sys.stdout.flush()\n",
    "    # initialize explainable score to zeros\n",
    "    W = np.zeros((len(users), len(items)))\n",
    "\n",
    "    for count, u in enumerate(users):            \n",
    "        candidate_items = user2user.find_user_candidate_items(u)        \n",
    "        for i in candidate_items:\n",
    "            user_who_rated_i, similar_user_who_rated_i = \\\n",
    "                user2user.similar_users_who_rated_this_item(u, i)\n",
    "            if user_who_rated_i.shape[0] == 0:\n",
    "                w = 0.0\n",
    "            else:\n",
    "                l1 = np.array([])\n",
    "                l2 = np.array([])\n",
    "                for v in user_who_rated_i[:5]:\n",
    "                    rvi = ratings.loc[(ratings['userid'] == v) & (ratings['itemid'] == i)]['rating'].tolist()[0]\n",
    "                    corr = calc_cor(user2user, ratings, u,v)\n",
    "                    l1 = np.append(l1,rvi * corr)\n",
    "                    l2 = np.append(l2,np.abs(corr))\n",
    "                if len(l2) == 0 or np.sum(l2) == 0:\n",
    "                    w = 0.0\n",
    "                else:\n",
    "                    w = np.sum(l1) / np.sum(l2)\n",
    "            W[u,i] =  w  if w > theta else 0.0\n",
    "        _progress(count)\n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4441a91-31e2-4591-90ef-cb31ba99bb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Explainable score. Progress status : 99.9%"
     ]
    }
   ],
   "source": [
    "W = explainable_score(user2user, users, items, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83fe3cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 3.16343332e-04, 1.89689195e-03, ...,\n",
       "       5.00000000e+00, 5.00000000e+00, 5.00000000e+00])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d412f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import sys\n",
    "import os\n",
    "\n",
    "DOWNLOAD_DESTINATION_DIR = \"dataset\"\n",
    "\n",
    "\n",
    "def unzip(name):\n",
    "    path = os.path.join(DOWNLOAD_DESTINATION_DIR, name)\n",
    "    print(f\"Unzipping the {name} zip file ...\")\n",
    "        \n",
    "    with zipfile.ZipFile(path, 'r') as data:\n",
    "        data.extractall(DOWNLOAD_DESTINATION_DIR)\n",
    "\n",
    "\n",
    "def _progress(count, block_size, total_size):\n",
    "    sys.stdout.write('\\rDownload data %.1f%%' % (float(count * block_size)/float(total_size) * 100.0))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def download(url, name):\n",
    "    path = os.path.join(DOWNLOAD_DESTINATION_DIR, name)\n",
    "    if not os.path.exists(path):        \n",
    "        os.makedirs(DOWNLOAD_DESTINATION_DIR, exist_ok=True)\n",
    "        fpath, _ = urllib.request.urlretrieve(url, filename=path, reporthook=_progress)\n",
    "        \n",
    "        print()\n",
    "        statinfo = os.stat(fpath)\n",
    "        print('Successfully downloaded', name, statinfo.st_size, 'bytes.')\n",
    "        unzip(name)\n",
    "\n",
    "\n",
    "class mlLatestSmall:\n",
    "\n",
    "    @staticmethod\n",
    "    def load():        \n",
    "        url = \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "        name = 'ml-latest-small'\n",
    "        \n",
    "        download(url, f\"{name}.zip\")\n",
    "        \n",
    "        ratings_path = os.path.join(DOWNLOAD_DESTINATION_DIR, name, 'ratings.csv')\n",
    "        ratings = pd.read_csv(\n",
    "            ratings_path,\n",
    "            sep=',',\n",
    "            names=[\"userid\", \"itemid\", \"rating\", \"timestamp\"],\n",
    "            skiprows=1\n",
    "        )\n",
    "\n",
    "        movies_path = os.path.join(DOWNLOAD_DESTINATION_DIR, name, 'movies.csv')\n",
    "        movies = pd.read_csv(\n",
    "            movies_path,\n",
    "            sep=',',\n",
    "            names=[\"itemid\", \"title\", \"genres\"],\n",
    "            encoding='latin-1',\n",
    "            skiprows=1\n",
    "        )\n",
    "        \n",
    "        return ratings, movies\n",
    "\n",
    "\n",
    "class ml100k:\n",
    "\n",
    "    @staticmethod\n",
    "    def load():        \n",
    "        url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "        name = 'ml-100k'\n",
    "        \n",
    "        download(url, f\"{name}.zip\")\n",
    "        \n",
    "        ratings_path = os.path.join(DOWNLOAD_DESTINATION_DIR, name, 'u.data')\n",
    "        ratings = pd.read_csv(\n",
    "            ratings_path,\n",
    "            sep='\\t',\n",
    "            names=[\"userid\", \"itemid\", \"rating\", \"timestamp\"],\n",
    "        )\n",
    "        ratings = ratings.sort_values(by=['userid', 'itemid']).reset_index(drop=True)\n",
    "        ratings = ratings.drop(columns=['timestamp'])\n",
    "\n",
    "        movies_columns = [\n",
    "            'itemid', 'title', 'release date', 'video release date', \n",
    "            'IMDb URL ', 'unknown', 'Action', 'Adventure', 'Animation',\n",
    "            \"Children's\", 'Comedy' , 'Crime' , 'Documentary' , 'Drama' , 'Fantasy' ,\n",
    "            'Film-Noir', 'Horror', 'Musical' , 'Mystery' , 'Romance' , 'Sci-Fi' ,\n",
    "            'Thriller' , 'War' , 'Western' ,\n",
    "        ]\n",
    "\n",
    "        movies_path = os.path.join(DOWNLOAD_DESTINATION_DIR, name, 'u.item')\n",
    "        movies = pd.read_csv(\n",
    "            movies_path,\n",
    "            sep='|',\n",
    "            names=movies_columns,\n",
    "            encoding='latin-1',\n",
    "        )\n",
    "        # drop non necessary columns. From the third to the last column\n",
    "        todrop = list(range(2, len(movies.columns)))\n",
    "        movies = movies.drop(movies.columns[todrop], axis=1)\n",
    "        \n",
    "        return ratings, movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af95cac-3c35-41cf-b288-8f561e2a100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, movies = ml100k.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a180fe18-d347-439f-94ad-cef3a68ad674",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = users[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d30715be-2e00-4202-9dcc-32875db66cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize users ratings ...\n",
      "Warning: make sure to name users column as userid, rating column as rating, item column as itemid.\n",
      "Initialize the similarity model ...\n",
      "Compute nearest neighbors ...\n",
      "User to user recommendation model created with success!\n"
     ]
    }
   ],
   "source": [
    "user2user = UserToUser(ratings, movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa944904-d592-4943-bcda-1c04254fc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_items = user2user.find_user_candidate_items(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6739b4d6-eb04-485e-bc66-25d9f857634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac171411-ecf5-4661-af35-0d3408eace5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, uencoder, iencoder = ids_encoder(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b1f07f7-e9f4-4ade-b050-a40b9e5b6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = sorted(ratings.userid.unique())\n",
    "items = sorted(ratings.itemid.unique())\n",
    "\n",
    "m = len(users)\n",
    "n = len(items)\n",
    "\n",
    "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
    "raw_examples, raw_labels = get_examples(ratings)\n",
    "\n",
    "# train test split\n",
    "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d4217a6d-ca48-40da-880e-1412ff1cc042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1775dc1-b9c5-42fc-995e-6e1c6f7288ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  itemid  rating\n",
       "0       0       0       5\n",
       "1       0       1       3\n",
       "2       0       2       4\n",
       "3       0       3       3\n",
       "4       0       4       3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe5b0a4a-1a5b-4b8c-9c54-35d2206fab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.01, beta=0.7, lamb=0.03, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6749b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training EMF\n",
      "k=10 \t alpha=0.01 \t beta=0.7 \t lambda=0.03\n",
      "epoch 1/50 - loss : 0.958 - val_loss : 1.055\n",
      "epoch 2/50 - loss : 0.837 - val_loss : 0.9\n",
      "epoch 3/50 - loss : 0.818 - val_loss : 0.869\n",
      "epoch 4/50 - loss : 0.812 - val_loss : 0.858\n",
      "epoch 5/50 - loss : 0.81 - val_loss : 0.852\n",
      "epoch 6/50 - loss : 0.809 - val_loss : 0.849\n",
      "epoch 7/50 - loss : 0.809 - val_loss : 0.847\n",
      "epoch 8/50 - loss : 0.809 - val_loss : 0.845\n",
      "epoch 9/50 - loss : 0.809 - val_loss : 0.844\n",
      "epoch 10/50 - loss : 0.809 - val_loss : 0.844\n",
      "epoch 11/50 - loss : 0.809 - val_loss : 0.843\n",
      "epoch 12/50 - loss : 0.809 - val_loss : 0.842\n",
      "epoch 13/50 - loss : 0.809 - val_loss : 0.842\n",
      "epoch 14/50 - loss : 0.809 - val_loss : 0.841\n",
      "epoch 15/50 - loss : 0.809 - val_loss : 0.841\n",
      "epoch 16/50 - loss : 0.809 - val_loss : 0.841\n",
      "epoch 17/50 - loss : 0.809 - val_loss : 0.841\n",
      "epoch 18/50 - loss : 0.809 - val_loss : 0.84\n",
      "epoch 19/50 - loss : 0.809 - val_loss : 0.84\n",
      "epoch 20/50 - loss : 0.809 - val_loss : 0.84\n",
      "epoch 21/50 - loss : 0.809 - val_loss : 0.84\n",
      "epoch 22/50 - loss : 0.809 - val_loss : 0.84\n",
      "epoch 23/50 - loss : 0.809 - val_loss : 0.84\n",
      "epoch 24/50 - loss : 0.809 - val_loss : 0.84\n",
      "epoch 25/50 - loss : 0.809 - val_loss : 0.839\n",
      "epoch 26/50 - loss : 0.809 - val_loss : 0.839\n",
      "epoch 27/50 - loss : 0.809 - val_loss : 0.839\n",
      "epoch 28/50 - loss : 0.809 - val_loss : 0.839\n",
      "epoch 29/50 - loss : 0.809 - val_loss : 0.839\n",
      "epoch 30/50 - loss : 0.809 - val_loss : 0.839\n",
      "epoch 31/50 - loss : 0.809 - val_loss : 0.839\n",
      "epoch 32/50 - loss : 0.809 - val_loss : 0.839\n",
      "epoch 33/50 - loss : 0.808 - val_loss : 0.839\n",
      "epoch 34/50 - loss : 0.808 - val_loss : 0.839\n",
      "epoch 35/50 - loss : 0.808 - val_loss : 0.839\n",
      "epoch 36/50 - loss : 0.808 - val_loss : 0.839\n",
      "epoch 37/50 - loss : 0.808 - val_loss : 0.839\n",
      "epoch 38/50 - loss : 0.808 - val_loss : 0.838\n",
      "epoch 39/50 - loss : 0.808 - val_loss : 0.838\n",
      "epoch 40/50 - loss : 0.808 - val_loss : 0.838\n",
      "epoch 41/50 - loss : 0.808 - val_loss : 0.838\n",
      "epoch 42/50 - loss : 0.808 - val_loss : 0.838\n",
      "epoch 43/50 - loss : 0.808 - val_loss : 0.838\n",
      "epoch 44/50 - loss : 0.808 - val_loss : 0.838\n",
      "epoch 45/50 - loss : 0.808 - val_loss : 0.838\n",
      "epoch 46/50 - loss : 0.808 - val_loss : 0.838\n",
      "epoch 47/50 - loss : 0.808 - val_loss : 0.838\n",
      "epoch 48/50 - loss : 0.808 - val_loss : 0.838\n",
      "epoch 49/50 - loss : 0.808 - val_loss : 0.838\n",
      "epoch 50/50 - loss : 0.808 - val_loss : 0.838\n"
     ]
    }
   ],
   "source": [
    "history = EMF.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff98d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for a,b in x_test:\n",
    "    predictions.append(EMF.predict(a,b,uencoder,iencoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ebf6ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [1,5,10,15,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c4fd4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_ids = np.array([a for a,b in x_test]).astype(int)\n",
    "test_movie_ids = np.array([b for a,b in x_test]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d8168f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcgs = []\n",
    "recalls = []\n",
    "mnaps = []\n",
    "\n",
    "for k in k_list:\n",
    "    ndcgs.append(EMF.calc_ndcg(np.array(predictions), k, test_user_ids, y_test, test_movie_ids))\n",
    "    recalls.append(EMF.calc_recalls(k,ratings, test_user_ids, uencoder, iencoder))\n",
    "    mnaps.append(EMF.calc_mnap(k,ratings, test_user_ids, uencoder, iencoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f41b4a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.532571249843209,\n",
       "  0.557032387502378,\n",
       "  0.578034987237875,\n",
       "  0.594817350828534,\n",
       "  0.615358043243442],\n",
       " [0.1424432, 0.1613423, 0.17798435, 0.1956721, 0.2351381],\n",
       " [0.3116,\n",
       "  0.16813266666666667,\n",
       "  0.14312070238095237,\n",
       "  0.12078960922410923,\n",
       "  0.12419097175296324])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcgs, recalls, mnaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f26c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64909839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35a3aaee-2b11-4c86-945c-2d94b4e6afbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training EMF\n",
      "k=7 \t alpha=0.01 \t beta=0.7 \t lambda=0.03\n",
      "epoch 1/5 - loss : 0.98 - val_loss : 1.058\n",
      "epoch 2/5 - loss : 0.843 - val_loss : 0.9\n",
      "epoch 3/5 - loss : 0.823 - val_loss : 0.87\n",
      "epoch 4/5 - loss : 0.816 - val_loss : 0.858\n",
      "epoch 5/5 - loss : 0.813 - val_loss : 0.852\n",
      "k: 7 score: 0.27791199999999994\n",
      "Training EMF\n",
      "k=10 \t alpha=0.01 \t beta=0.7 \t lambda=0.03\n",
      "epoch 1/5 - loss : 0.958 - val_loss : 1.055\n",
      "epoch 2/5 - loss : 0.837 - val_loss : 0.9\n",
      "epoch 3/5 - loss : 0.818 - val_loss : 0.869\n",
      "epoch 4/5 - loss : 0.812 - val_loss : 0.858\n",
      "epoch 5/5 - loss : 0.81 - val_loss : 0.852\n",
      "k: 10 score: 0.11685466666666666\n",
      "Training EMF\n",
      "k=13 \t alpha=0.01 \t beta=0.7 \t lambda=0.03\n",
      "epoch 1/5 - loss : 0.93 - val_loss : 1.045\n",
      "epoch 2/5 - loss : 0.829 - val_loss : 0.905\n",
      "epoch 3/5 - loss : 0.813 - val_loss : 0.873\n",
      "epoch 4/5 - loss : 0.808 - val_loss : 0.861\n",
      "epoch 5/5 - loss : 0.807 - val_loss : 0.854\n",
      "k: 13 score: 0.108135\n",
      "Training EMF\n",
      "k=16 \t alpha=0.01 \t beta=0.7 \t lambda=0.03\n",
      "epoch 1/5 - loss : 0.917 - val_loss : 1.057\n",
      "epoch 2/5 - loss : 0.818 - val_loss : 0.911\n",
      "epoch 3/5 - loss : 0.804 - val_loss : 0.876\n",
      "epoch 4/5 - loss : 0.802 - val_loss : 0.862\n",
      "epoch 5/5 - loss : 0.802 - val_loss : 0.855\n",
      "k: 16 score: 0.06143466666666667\n",
      "Training EMF\n",
      "k=20 \t alpha=0.01 \t beta=0.7 \t lambda=0.03\n",
      "epoch 1/5 - loss : 0.91 - val_loss : 1.09\n",
      "epoch 2/5 - loss : 0.81 - val_loss : 0.924\n",
      "epoch 3/5 - loss : 0.798 - val_loss : 0.882\n",
      "epoch 4/5 - loss : 0.796 - val_loss : 0.865\n",
      "epoch 5/5 - loss : 0.796 - val_loss : 0.856\n",
      "k: 20 score: 0.028439999999999997\n"
     ]
    }
   ],
   "source": [
    "for k in [7,10,13,16,20]:\n",
    "    EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.01, beta=0.7, lamb=0.03, k=k)\n",
    "    EMF.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "    ratings, uencoder, iencoder = ids_encoder(ratings)\n",
    "    val = EMF.calc_mnap(5,ratings, test_user_ids, uencoder, iencoder)\n",
    "    print('k:',k, 'score:',val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c07fd723-ab29-4662-9281-fbebee5a2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_params = dict()\n",
    "tuning_params = { \n",
    "#  \"k\":(7,25)\n",
    "  \"lamb\": (0.01,0.1)\n",
    "#  \"beta\": (0.4,0.8)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75406703-bde5-4628-a88b-16bcddea7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(lamb):\n",
    "    \n",
    "    rat, movies = ml100k.load()\n",
    "    ratings, uencoder, iencoder = ids_encoder(rat)\n",
    "    \n",
    "    users = sorted(ratings.userid.unique())\n",
    "    items = sorted(ratings.itemid.unique())\n",
    "\n",
    "    m = len(users)\n",
    "    n = len(items)\n",
    "\n",
    "    # get examples as tuples of userids and itemids and labels from normalize ratings\n",
    "    raw_examples, raw_labels = get_examples(ratings)\n",
    "\n",
    "    # train test split\n",
    "    (x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
    "    \n",
    "    recommender = ExplainableMatrixFactorization(943, 1682, W, alpha=0.01, beta=0.7, lamb=lamb, k=7)\n",
    "    recommender.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "    ratings, uencoder, iencoder = ids_encoder(rat)\n",
    "    predictions = []\n",
    "    for a,b in x_test:\n",
    "        predictions.append(EMF.predict(a,b,uencoder,iencoder))\n",
    "    \n",
    "#    val = recommender.calc_mnap(5,ratings, test_user_ids, uencoder, iencoder)\n",
    "#    val1 = recommender.calc_recalls(5,ratings, test_user_ids, uencoder, iencoder)\n",
    "    val2 = recommender.calc_ndcg(np.array(predictions), 5, test_user_ids, y_test, test_movie_ids)/2\n",
    "\n",
    "    return val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5a631d7-3c70-4909-81a0-d24a94fb80c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   lamb    |\n",
      "-------------------------------------\n",
      "Training EMF\n",
      "k=7 \t alpha=0.01 \t beta=0.7 \t lambda=0.059571811231711805\n",
      "epoch 1/5 - loss : 0.98 - val_loss : 1.058\n",
      "epoch 2/5 - loss : 0.843 - val_loss : 0.9\n",
      "epoch 3/5 - loss : 0.823 - val_loss : 0.87\n",
      "epoch 4/5 - loss : 0.816 - val_loss : 0.858\n",
      "epoch 5/5 - loss : 0.813 - val_loss : 0.852\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.459   \u001b[0m | \u001b[0m 0.05957 \u001b[0m |\n",
      "Training EMF\n",
      "k=7 \t alpha=0.01 \t beta=0.7 \t lambda=0.07373330403562944\n",
      "epoch 1/5 - loss : 0.98 - val_loss : 1.058\n",
      "epoch 2/5 - loss : 0.843 - val_loss : 0.9\n",
      "epoch 3/5 - loss : 0.823 - val_loss : 0.87\n",
      "epoch 4/5 - loss : 0.816 - val_loss : 0.858\n",
      "epoch 5/5 - loss : 0.813 - val_loss : 0.852\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.459   \u001b[0m | \u001b[0m 0.07373 \u001b[0m |\n",
      "Training EMF\n",
      "k=7 \t alpha=0.01 \t beta=0.7 \t lambda=0.03618142650216499\n",
      "epoch 1/5 - loss : 0.98 - val_loss : 1.058\n",
      "epoch 2/5 - loss : 0.843 - val_loss : 0.9\n",
      "epoch 3/5 - loss : 0.823 - val_loss : 0.87\n",
      "epoch 4/5 - loss : 0.816 - val_loss : 0.858\n",
      "epoch 5/5 - loss : 0.813 - val_loss : 0.852\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.459   \u001b[0m | \u001b[0m 0.03618 \u001b[0m |\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:179\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_queue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:25\u001b[0m, in \u001b[0;36mQueue.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueue is empty, no more objects to retrieve.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbayes_opt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianOptimization\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[1;32m      4\u001b[0m   f \u001b[38;5;241m=\u001b[39m func1,\n\u001b[1;32m      5\u001b[0m   pbounds \u001b[38;5;241m=\u001b[39m tuning_params,\n\u001b[1;32m      6\u001b[0m   random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, \n\u001b[1;32m      7\u001b[0m  )\n\u001b[0;32m----> 9\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[43minit_points\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:182\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     util\u001b[38;5;241m.\u001b[39mupdate_params()\n\u001b[0;32m--> 182\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mutil\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:131\u001b[0m, in \u001b[0;36mBayesianOptimization.suggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gp\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Finding argmax of the acquisition function.\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m suggestion \u001b[38;5;241m=\u001b[39m \u001b[43macq_max\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutility_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutility\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_random_state\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39marray_to_params(suggestion)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/bayes_opt/util.py:65\u001b[0m, in \u001b[0;36macq_max\u001b[0;34m(ac, gp, y_max, bounds, random_state, n_warmup, n_iter)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Store it if better than previous minimum(maximum).\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_acq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_acq:\n\u001b[1;32m     66\u001b[0m     x_max \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m     67\u001b[0m     max_acq \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mres\u001b[38;5;241m.\u001b[39mfun[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "  f = func1,\n",
    "  pbounds = tuning_params,\n",
    "  random_state = 3, \n",
    " )\n",
    "\n",
    "optimizer.maximize(\n",
    "  init_points = 3,\n",
    "  n_iter = 4, \n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2d1cbb8a-27f1-4a78-b1a6-00075776d095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.11861233333333335, 'params': {'beta': 0.7674443631751686}}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb39fcb-6c07-4710-9936-e3c88bad0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = optimizer.max['params']['beta']\n",
    "lamb = optimizer.max['params']['lamb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "797760f3-542e-47d4-9e5f-27383160b081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training EMF\n",
      "k=10 \t alpha=0.01 \t beta=0.75 \t lambda=0.03\n",
      "epoch 1/10 - loss : 0.968 - val_loss : 1.062\n",
      "epoch 2/10 - loss : 0.847 - val_loss : 0.907\n",
      "epoch 3/10 - loss : 0.828 - val_loss : 0.877\n",
      "epoch 4/10 - loss : 0.823 - val_loss : 0.866\n",
      "epoch 5/10 - loss : 0.82 - val_loss : 0.86\n",
      "epoch 6/10 - loss : 0.82 - val_loss : 0.857\n",
      "epoch 7/10 - loss : 0.819 - val_loss : 0.855\n",
      "epoch 8/10 - loss : 0.819 - val_loss : 0.854\n",
      "epoch 9/10 - loss : 0.819 - val_loss : 0.853\n",
      "epoch 10/10 - loss : 0.819 - val_loss : 0.852\n"
     ]
    }
   ],
   "source": [
    "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.01, beta=0.75, lamb=0.03, k=10)\n",
    "\n",
    "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8744cc6f-7f91-4e07-9960-de4e6237192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_ids = np.array([a for a,b in x_test]).astype(int)\n",
    "test_movie_ids = np.array([b for a,b in x_test]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a22322d9-debc-4bbe-87f4-a20057657b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for a,b in x_test:\n",
    "    predictions.append(EMF.predict(a,b,uencoder,iencoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f864b008-d361-4221-ad09-127cf708b664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.314878112508595,\n",
       " 3.319415207445759,\n",
       " 2.72246692013486,\n",
       " 4.21325621302688,\n",
       " 2.668411206363998]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb58ab4f-f6b8-471a-8fa0-7e986bfd08e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation error : 0.797\n"
     ]
    }
   ],
   "source": [
    "EMF.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480892d8-8925-45bc-895f-06333be3bff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
